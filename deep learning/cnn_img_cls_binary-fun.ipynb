{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "77a0c01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3932dbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Load & split the dataset\n",
    "(X_train_full, y_train_full), (X_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\n",
    "X_train, y_train = X_train_full[:-5000], y_train_full[:-5000]\n",
    "X_valid, y_valid = X_train_full[-5000:], y_train_full[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23dba8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 28, 28, 1) (55000,)\n",
      "(5000, 28, 28, 1) (5000,)\n",
      "(10000, 28, 28, 1) (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4c9b6233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Add the channel dimension (reshape)\n",
    "X_train = X_train[..., np.newaxis]\n",
    "X_valid = X_valid[..., np.newaxis]\n",
    "X_test  = X_test[...,  np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ff6eb4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Convert to float32 and scale pixels to [0,1]\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_valid = X_valid.astype(\"float32\") / 255.0\n",
    "X_test  = X_test.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "72f01cf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(2, 2))  # Smaller size\n",
    "plt.imshow(X_train[0], cmap=\"binary\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "669196a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Build the CNN with Functional API\n",
    "inputs = layers.Input(shape=(28, 28, 1), name=\"input_image\")\n",
    "\n",
    "# # Normalize inside the model\n",
    "# x = layers.Rescaling(1./255, name=\"rescale\")(inputs)\n",
    "x = inputs\n",
    "\n",
    "# Convolutional feature extractor\n",
    "x = layers.Conv2D(32, (3,3), activation=\"relu\", name=\"conv1\")(x)\n",
    "x = layers.MaxPooling2D((2,2), name=\"pool1\")(x)\n",
    "x = layers.Conv2D(64, (3,3), activation=\"relu\", name=\"conv2\")(x)\n",
    "x = layers.MaxPooling2D((2,2), name=\"pool2\")(x)\n",
    "x = layers.Conv2D(64, (3,3), activation=\"relu\", name=\"conv3\")(x)\n",
    "\n",
    "# Classification head\n",
    "x = layers.Flatten(name=\"flatten\")(x)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense1\")(x)\n",
    "x = layers.Dropout(0.5, name=\"dropout\")(x)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"output_probs\")(x)\n",
    "\n",
    "model = Model(inputs, outputs, name=\"fashion_mnist_cnn\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5e7caf6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"fashion_mnist_cnn\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 28, 28, 1)]       0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " pool1 (MaxPooling2D)        (None, 13, 13, 32)        0         \n",
      "                                                                 \n",
      " conv2 (Conv2D)              (None, 11, 11, 64)        18496     \n",
      "                                                                 \n",
      " pool2 (MaxPooling2D)        (None, 5, 5, 64)          0         \n",
      "                                                                 \n",
      " conv3 (Conv2D)              (None, 3, 3, 64)          36928     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 576)               0         \n",
      "                                                                 \n",
      " dense1 (Dense)              (None, 64)                36928     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 64)                0         \n",
      "                                                                 \n",
      " output_probs (Dense)        (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 93322 (364.54 KB)\n",
      "Trainable params: 93322 (364.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 4) Compile\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "82855a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.6874 - accuracy: 0.7508 - val_loss: 0.3961 - val_accuracy: 0.8520\n",
      "Epoch 2/10\n",
      "1719/1719 [==============================] - 15s 9ms/step - loss: 0.4439 - accuracy: 0.8446 - val_loss: 0.3418 - val_accuracy: 0.8702\n",
      "Epoch 3/10\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.3713 - accuracy: 0.8698 - val_loss: 0.3099 - val_accuracy: 0.8876\n",
      "Epoch 4/10\n",
      "1719/1719 [==============================] - 16s 9ms/step - loss: 0.3308 - accuracy: 0.8835 - val_loss: 0.2832 - val_accuracy: 0.8992\n",
      "Epoch 5/10\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.3000 - accuracy: 0.8930 - val_loss: 0.2663 - val_accuracy: 0.9028\n",
      "Epoch 6/10\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.2786 - accuracy: 0.9005 - val_loss: 0.2535 - val_accuracy: 0.9064\n",
      "Epoch 7/10\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.2614 - accuracy: 0.9076 - val_loss: 0.2519 - val_accuracy: 0.9060\n",
      "Epoch 8/10\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.2470 - accuracy: 0.9121 - val_loss: 0.2500 - val_accuracy: 0.9084\n",
      "Epoch 9/10\n",
      "1719/1719 [==============================] - 16s 10ms/step - loss: 0.2331 - accuracy: 0.9159 - val_loss: 0.2487 - val_accuracy: 0.9080\n",
      "Epoch 10/10\n",
      "1719/1719 [==============================] - 17s 10ms/step - loss: 0.2197 - accuracy: 0.9217 - val_loss: 0.2465 - val_accuracy: 0.9098\n"
     ]
    }
   ],
   "source": [
    "# 5) Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=10,\n",
    "    validation_data=(X_valid, y_valid)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b82b7a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2778 - accuracy: 0.9019\n",
      "\n",
      "Test accuracy: 0.9019\n"
     ]
    }
   ],
   "source": [
    "# 6) Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8ee4110d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 79ms/step\n",
      "[[0.   0.   0.   0.   0.   0.   0.   0.   0.   1.  ]\n",
      " [0.   0.   1.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   1.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.05 0.   0.01 0.   0.01 0.   0.93 0.   0.   0.  ]]\n",
      "Sample 0: Predicted=9, True=9\n",
      "Sample 1: Predicted=2, True=2\n",
      "Sample 2: Predicted=1, True=1\n",
      "Sample 3: Predicted=1, True=1\n",
      "Sample 4: Predicted=6, True=6\n"
     ]
    }
   ],
   "source": [
    "# 7) Predict on a few samples\n",
    "sample_images = X_test[:5]\n",
    "sample_labels = y_test[:5]\n",
    "pred_probs = model.predict(sample_images)\n",
    "print(pred_probs.round(2))\n",
    "pred_labels = np.argmax(pred_probs, axis=1)\n",
    "\n",
    "for i, (pred, true) in enumerate(zip(pred_labels, sample_labels)):\n",
    "    print(f\"Sample {i}: Predicted={pred}, True={true}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dcec2972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6], dtype=int64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = pred_probs.argmax(axis=-1)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b97c1181",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [\"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "               \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "24b3f4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ankle boot', 'Pullover', 'Trouser', 'Trouser', 'Shirt'],\n",
       "      dtype='<U11')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(class_names)[y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87ff0a05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9, 2, 1, 1, 6], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new = y_test[:5]\n",
    "y_new"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
