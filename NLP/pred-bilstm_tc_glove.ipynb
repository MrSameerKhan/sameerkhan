{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83aa3d3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 1 — Imports & Configuration\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import TextVectorization\n",
    "\n",
    "# (Must match training)\n",
    "MAX_SEQUENCE_LEN = 200\n",
    "MODEL_PATH       = \"D:/AIML/data/bilstm_tc_fun_glove.h5\"\n",
    "VOCAB_PATH       = \"D:/AIML/data/agnews_vocab.txt\"\n",
    "CLASS_NAMES      = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6ce7fab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"bilstm_glove\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_tokens (InputLayer)   [(None, 200)]             0         \n",
      "                                                                 \n",
      " embedding_5 (Embedding)     (None, 200, 300)          6000000   \n",
      "                                                                 \n",
      " bidirectional (Bidirection  (None, 200, 128)          186880    \n",
      " al)                                                             \n",
      "                                                                 \n",
      " bidirectional_1 (Bidirecti  (None, 128)               98816     \n",
      " onal)                                                           \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4)                 260       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 6294212 (24.01 MB)\n",
      "Trainable params: 294212 (1.12 MB)\n",
      "Non-trainable params: 6000000 (22.89 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 2 — Load Your Trained Model\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "model = tf.keras.models.load_model(MODEL_PATH)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc50d81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 19999\n",
      "First 10 tokens: ['[UNK]', 'the', 'to', 'a', 'of', 'in', 'and', 'on', 'for', '39s']\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 3 — Reconstruct the TextVectorization Layer\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# 3.1 Create the layer exactly as in training (no max_tokens argument needed)\n",
    "vectorizer = TextVectorization(\n",
    "    output_mode=\"int\",\n",
    "    output_sequence_length=MAX_SEQUENCE_LEN\n",
    ")\n",
    "\n",
    "# 3.2 Load and set the saved vocabulary\n",
    "with open(VOCAB_PATH, encoding=\"utf8\") as f:\n",
    "    vocab = [line.strip() for line in f if line.strip()]\n",
    "vectorizer.set_vocabulary(vocab)\n",
    "\n",
    "# Quick vocab sanity check\n",
    "print(\"Vocabulary size:\", len(vocab))\n",
    "print(\"First 10 tokens:\", vocab[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a1456dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 4 — Helper to Encode Raw Text\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def encode(text: str) -> tf.Tensor:\n",
    "    \"\"\"\n",
    "    Turn a single raw string into a tensor of shape (1, MAX_SEQUENCE_LEN)\n",
    "    of integer token IDs.\n",
    "    \"\"\"\n",
    "    return vectorizer(tf.constant([text]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e1979b42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 5 — Prediction Function\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "def predict(text: str):\n",
    "    \"\"\"\n",
    "    Runs the model on the input text, returning:\n",
    "      - predicted class name\n",
    "      - confidence of that prediction\n",
    "      - full probability vector\n",
    "    \"\"\"\n",
    "    seq   = encode(text)             # shape (1, MAX_SEQUENCE_LEN)\n",
    "    probs = model.predict(seq)[0]    # shape (NUM_CLASSES,)\n",
    "    idx   = int(np.argmax(probs))    # index of highest probability\n",
    "    return {\n",
    "        \"text\": text,\n",
    "        \"predicted_class\": CLASS_NAMES[idx],\n",
    "        \"confidence\": float(probs[idx]),\n",
    "        \"all_probs\": probs\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e021975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 4s 4s/step\n",
      "Text: NASA announces new rover mission to study lunar surface.…\n",
      "Predicted: Business  (confidence 81.2%)\n",
      "\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "Text: Manchester United win the Champions League final.…\n",
      "Predicted: Sports  (confidence 43.7%)\n",
      "\n",
      "1/1 [==============================] - 0s 41ms/step\n",
      "Text: Wall Street rallies after strong tech earnings report.…\n",
      "Predicted: Sci/Tech  (confidence 66.8%)\n",
      "\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "Text: Researchers develop AI model that can learn from small data.…\n",
      "Predicted: Sports  (confidence 74.3%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "# Cell 6 — Demo on Example Sentences\n",
    "# ────────────────────────────────────────────────────────────────────────────────\n",
    "examples = [\n",
    "    \"NASA announces new rover mission to study lunar surface.\",\n",
    "    \"Manchester United win the Champions League final.\",\n",
    "    \"Wall Street rallies after strong tech earnings report.\",\n",
    "    \"Researchers develop AI model that can learn from small data.\"\n",
    "]\n",
    "\n",
    "for ex in examples:\n",
    "    result = predict(ex)\n",
    "    print(f\"Text: {result['text'][:80]}…\")\n",
    "    print(f\"Predicted: {result['predicted_class']}  \"\n",
    "          f\"(confidence {result['confidence']:.1%})\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
