{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d3d105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import *\n",
    "import string\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "daa6bed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set count: 120000\n",
      "+-----+-------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|label|                                                                    title|                                                                                         description|\n",
      "+-----+-------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|    3|                        Wall St. Bears Claw Back Into the Black (Reuters)|      Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.|\n",
      "|    3|                      Carlyle Looks Toward Commercial Aerospace (Reuters)|Reuters - Private investment firm Carlyle Group,\\which has a reputation for making well-timed and...|\n",
      "|    3|                          Oil and Economy Cloud Stocks' Outlook (Reuters)|Reuters - Soaring crude prices plus worries\\about the economy and the outlook for earnings are ex...|\n",
      "|    3|             Iraq Halts Oil Exports from Main Southern Pipeline (Reuters)|Reuters - Authorities have halted oil export\\flows from the main pipeline in southern Iraq after\\...|\n",
      "|    3|Oil prices soar to all-time record, posing new menace to US economy (AFP)|AFP - Tearaway world oil prices, toppling records and straining wallets, present a new economic m...|\n",
      "+-----+-------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Test set count: 7600\n",
      "+-----+--------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|label|                                                                                 title|                                                                                         description|\n",
      "+-----+--------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "|    3|                                                     Fears for T N pension after talks|Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stric...|\n",
      "|    4|The Race is On: Second Private Team Sets Launch Date for Human Spaceflight (SPACE.com)|SPACE.com - TORONTO, Canada -- A second\\team of rocketeers competing for the  #36;10 million Ansa...|\n",
      "|    4|                                         Ky. Company Wins Grant to Study Peptides (AP)|AP - A company founded by a chemistry researcher at the University of Louisville won a grant to d...|\n",
      "|    4|                                         Prediction Unit Helps Forecast Wildfires (AP)|AP - It's barely dawn when Mike Fitzpatrick starts his shift with a blur of colorful maps, figure...|\n",
      "|    4|                                           Calif. Aims to Limit Farm-Related Smog (AP)|AP - Southern California's smog-fighting agency went after emissions of the bovine variety Friday...|\n",
      "+-----+--------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2.1 Start Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"AGNewsTextClassification\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# 2.2 Define the schema\n",
    "schema = StructType([\n",
    "    StructField(\"label\",       IntegerType(), nullable=False),\n",
    "    StructField(\"title\",       StringType(),  nullable=True),\n",
    "    StructField(\"description\", StringType(),  nullable=True),\n",
    "])\n",
    "\n",
    "# 2.3 Read the CSVs\n",
    "train_df = spark.read.csv(\n",
    "    \"D:/AIML/data/ag_news_train.csv\",\n",
    "    schema=schema,\n",
    "    header=False\n",
    ")\n",
    "test_df = spark.read.csv(\n",
    "    \"D:/AIML/data/ag_news_test.csv\",\n",
    "    schema=schema,\n",
    "    header=False\n",
    ")\n",
    "\n",
    "# 2.4 Quick sanity-check\n",
    "print(\"Train set count:\", train_df.count())\n",
    "train_df.show(5, truncate=100)\n",
    "\n",
    "print(\"Test set count:\", test_df.count())\n",
    "test_df.show(5, truncate=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11a6870e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|label|count|\n",
      "+-----+-----+\n",
      "|    1|30000|\n",
      "|    2|30000|\n",
      "|    3|30000|\n",
      "|    4|30000|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# (train_df.groupby(\"label\").count()).show()\n",
    "train_df.groupBy(\"label\").count().orderBy(\"label\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd4a61f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def preprocess_text(text):\n",
    "#     text = text.lower()\n",
    "#     stop_word = [\"false\", \"true\"]\n",
    "#     text = text.replace('\\n', ' ').replace('\\\\u', ' ').replace('\\\\', ' ')\n",
    "#     text = text.replace('  ', ' ')\n",
    "#     text = text.translate(str.maketrans('','',string.punctuation))\n",
    "\n",
    "#     result_words = ' '.join([x for x in text.split() if len(x) >=1 and x in stop_word])\n",
    "#     return result_words\n",
    "# preprocess_text_udf = udf(preprocess_text, StringType())\n",
    "\n",
    "# train_text_df = train_df.withColumn('preprocessed_text', preprocess_text_udf('description'))\n",
    "\n",
    "\n",
    "# print(train_text_df.columns)\n",
    "# print(\"Train set count:\", train_text_df.count())\n",
    "# train_text_df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c230763d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|                                                                     description|                                                               preprocessed_text|\n",
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are se...|reuters short sellers wall street s dwindling band of ultra cynics are seeing...|\n",
      "|Reuters - Private investment firm Carlyle Group,\\which has a reputation for m...|reuters private investment firm carlyle group which has a reputation for maki...|\n",
      "|Reuters - Soaring crude prices plus worries\\about the economy and the outlook...|reuters soaring crude prices plus worries about the economy and the outlook f...|\n",
      "|Reuters - Authorities have halted oil export\\flows from the main pipeline in ...|reuters authorities have halted oil export flows from the main pipeline in so...|\n",
      "|AFP - Tearaway world oil prices, toppling records and straining wallets, pres...|afp tearaway world oil prices toppling records and straining wallets present ...|\n",
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|                                                                     description|                                                               preprocessed_text|\n",
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "|Unions representing workers at Turner   Newall say they are 'disappointed' af...|unions representing workers at turner newall say they are disappointed after ...|\n",
      "|SPACE.com - TORONTO, Canada -- A second\\team of rocketeers competing for the ...|space com toronto canada a second team of rocketeers competing for the 36 10 ...|\n",
      "|AP - A company founded by a chemistry researcher at the University of Louisvi...|ap a company founded by a chemistry researcher at the university of louisvill...|\n",
      "|AP - It's barely dawn when Mike Fitzpatrick starts his shift with a blur of c...|ap it s barely dawn when mike fitzpatrick starts his shift with a blur of col...|\n",
      "|AP - Southern California's smog-fighting agency went after emissions of the b...|ap southern california s smog fighting agency went after emissions of the bov...|\n",
      "+--------------------------------------------------------------------------------+--------------------------------------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, lower, regexp_replace, trim\n",
    "\n",
    "train_text_df = train_df.withColumn(\n",
    "    \"preprocessed_text\",\n",
    "    trim(\n",
    "      # collapse multiple spaces after all replacements\n",
    "      regexp_replace(\n",
    "        # remove the words “false” or “true”\n",
    "        regexp_replace(\n",
    "          # collapse repeating whitespace\n",
    "          regexp_replace(\n",
    "            # remove all punctuation (anything not a word character or whitespace)\n",
    "            regexp_replace(lower(col(\"description\")),\n",
    "                           r\"[^\\w\\s]\", \" \"),\n",
    "            r\"\\s+\", \" \"\n",
    "          ),\n",
    "          r\"\\b(false|true)\\b\", \"\"\n",
    "        ),\n",
    "        r\"\\s+\", \" \"\n",
    "      )\n",
    "    )\n",
    ")\n",
    "\n",
    "test_text_df = test_df.withColumn(\n",
    "    \"preprocessed_text\",\n",
    "    trim(\n",
    "      # collapse multiple spaces after all replacements\n",
    "      regexp_replace(\n",
    "        # remove the words “false” or “true”\n",
    "        regexp_replace(\n",
    "          # collapse repeating whitespace\n",
    "          regexp_replace(\n",
    "            # remove all punctuation (anything not a word character or whitespace)\n",
    "            regexp_replace(lower(col(\"description\")),\n",
    "                           r\"[^\\w\\s]\", \" \"),\n",
    "            r\"\\s+\", \" \"\n",
    "          ),\n",
    "          r\"\\b(false|true)\\b\", \"\"\n",
    "        ),\n",
    "        r\"\\s+\", \" \"\n",
    "      )\n",
    "    )\n",
    ")\n",
    "\n",
    "train_text_df.select(\"description\", \"preprocessed_text\").show(5, truncate=80)\n",
    "test_text_df.select(\"description\", \"preprocessed_text\").show(5, truncate=80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "130dc8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pyspark.sql.functions import udf\n",
    "# from pyspark.sql.types import ArrayType, StringType\n",
    "\n",
    "# # 0) Define your maximum token length\n",
    "# MAX_LEN = 512\n",
    "\n",
    "# # 1) Define the splitting + padding/truncation function\n",
    "# def get_split(text):\n",
    "#     text_split = text.split()\n",
    "#     if len(text_split) <= MAX_LEN:\n",
    "#         text_split = text_split[:MAX_LEN] + [\"BLANK\"] * (MAX_LEN - len(text_split[:MAX_LEN]))\n",
    "#         return text_split\n",
    "#     else:\n",
    "#         text_list = []\n",
    "#         text_list.extend(text_split[:int(MAX_LEN/2)])\n",
    "#         text_list.extend(text_split[-int(MAX_LEN/2):])\n",
    "\n",
    "#     return text_list\n",
    "\n",
    "# # 2) Wrap it as a Spark UDF returning ArrayType(StringType)\n",
    "# get_split_udf = udf(get_split, ArrayType(StringType()))\n",
    "\n",
    "# # 3) Apply to your DataFrames\n",
    "# #    (assumes you already have `train_text_df`, `val_text_df`, `test_text_df`\n",
    "# #     and each has a column \"preprocessed_text\" of type String)\n",
    "# train_text_df = train_text_df.withColumn(\n",
    "#     \"tokenized_text\",\n",
    "#     get_split_udf(\"preprocessed_text\")\n",
    "# )\n",
    "# test_text_df = test_text_df.withColumn(\n",
    "#     \"tokenized_text\",\n",
    "#     get_split_udf(\"preprocessed_text\")\n",
    "# )\n",
    "\n",
    "# # 4) Peek at the results\n",
    "# train_text_df.select(\"preprocessed_text\", \"tokenized_text\").show(5, truncate=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9161aca8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                 preprocessed_text|                                    tokenized_text|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|reuters short sellers wall street s dwindling b...|[reuters, short, sellers, wall, street, s, dwin...|\n",
      "|reuters private investment firm carlyle group w...|[reuters, private, investment, firm, carlyle, g...|\n",
      "|reuters soaring crude prices plus worries about...|[reuters, soaring, crude, prices, plus, worries...|\n",
      "|reuters authorities have halted oil export flow...|[reuters, authorities, have, halted, oil, expor...|\n",
      "|afp tearaway world oil prices toppling records ...|[afp, tearaway, world, oil, prices, toppling, r...|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|                                 preprocessed_text|                                    tokenized_text|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "|unions representing workers at turner newall sa...|[unions, representing, workers, at, turner, new...|\n",
      "|space com toronto canada a second team of rocke...|[space, com, toronto, canada, a, second, team, ...|\n",
      "|ap a company founded by a chemistry researcher ...|[ap, a, company, founded, by, a, chemistry, res...|\n",
      "|ap it s barely dawn when mike fitzpatrick start...|[ap, it, s, barely, dawn, when, mike, fitzpatri...|\n",
      "|ap southern california s smog fighting agency w...|[ap, southern, california, s, smog, fighting, a...|\n",
      "+--------------------------------------------------+--------------------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import (\n",
    "    split, size, when, array_repeat, slice, col,\n",
    "    concat, lit\n",
    ")\n",
    "\n",
    "MAX_LEN = 512\n",
    "half    = MAX_LEN // 2\n",
    "\n",
    "train_text_df = train_text_df.withColumn(\"tokens\", split(col(\"preprocessed_text\"), r\"\\s+\")).withColumn(\"tokenized_text\",\n",
    "    when(\n",
    "      size(col(\"tokens\")) <= MAX_LEN,\n",
    "      # pad the tokens array up to MAX_LEN with \"BLANK\"\n",
    "      concat(\n",
    "        col(\"tokens\"),\n",
    "        array_repeat(lit(\"BLANK\"), MAX_LEN - size(col(\"tokens\")))\n",
    "      )\n",
    "    ).otherwise(\n",
    "      # if too long, take first half and last half\n",
    "      concat(\n",
    "        slice(col(\"tokens\"), 1, half),\n",
    "        slice(col(\"tokens\"), -half, half)\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "\n",
    "# inspect\n",
    "train_text_df.select(\"preprocessed_text\",\"tokenized_text\").show(5, truncate=50)\n",
    "\n",
    "\n",
    "\n",
    "test_text_df = test_text_df.withColumn(\"tokens\", split(col(\"preprocessed_text\"), r\"\\s+\")).withColumn(\"tokenized_text\",\n",
    "    when(\n",
    "      size(col(\"tokens\")) <= MAX_LEN,\n",
    "      # pad the tokens array up to MAX_LEN with \"BLANK\"\n",
    "      concat(\n",
    "        col(\"tokens\"),\n",
    "        array_repeat(lit(\"BLANK\"), MAX_LEN - size(col(\"tokens\")))\n",
    "      )\n",
    "    ).otherwise(\n",
    "      # if too long, take first half and last half\n",
    "      concat(\n",
    "        slice(col(\"tokens\"), 1, half),\n",
    "        slice(col(\"tokens\"), -half, half)\n",
    "      )\n",
    "    )\n",
    "  )\n",
    "\n",
    "# inspect\n",
    "test_text_df.select(\"preprocessed_text\",\"tokenized_text\").show(5, truncate=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d10420c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('label', 'int'),\n",
       " ('title', 'string'),\n",
       " ('description', 'string'),\n",
       " ('preprocessed_text', 'string'),\n",
       " ('tokens', 'array<string>'),\n",
       " ('tokenized_text', 'array<string>')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_text_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11d8ad81",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnpicklingError",
     "evalue": "invalid load key, ','.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnpicklingError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m text_indexer_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/AIML/data/glove.42B.300d.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(text_indexer_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[1;32m----> 4\u001b[0m     word_index \u001b[38;5;241m=\u001b[39m \u001b[43mpickle\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mD:/AIML/data/text_mapping.pickle\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m handle:\n\u001b[0;32m      7\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(word_index, handle, protocol\u001b[38;5;241m=\u001b[39mpickle\u001b[38;5;241m.\u001b[39mHIGHEST_PROTOCOL)\n",
      "\u001b[1;31mUnpicklingError\u001b[0m: invalid load key, ','."
     ]
    }
   ],
   "source": [
    "text_indexer_path = \"D:/AIML/data/glove.42B.300d.txt\"\n",
    "\n",
    "with open(text_indexer_path, 'rb') as handle:\n",
    "    word_index = pickle.load(handle)\n",
    "\n",
    "with open(\"D:/AIML/data/text_mapping.pickle\", 'wb') as handle:\n",
    "    pickle.dump(word_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "np.save(\"D:/AIML/data/text_mapping.npy\", word_index, allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3ca01450",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'word_index' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m UNK_IDX \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# broadcast it so that every executor can look up tokens quickly\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m word_index_bc \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msparkContext\u001b[38;5;241m.\u001b[39mbroadcast(\u001b[43mword_index\u001b[49m)\n\u001b[0;32m     13\u001b[0m MAX_LEN \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m512\u001b[39m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 1) define a Python function to map & pad/truncate\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'word_index' is not defined"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import udf, col\n",
    "from pyspark.sql.types import ArrayType, IntegerType\n",
    "\n",
    "# 0) your precomputed Python dict { token_str → integer_index }\n",
    "#    e.g. word_index = { \"<PAD>\":0, \"<UNK>\":1, \"the\": 2, \"dog\": 3, … }\n",
    "#    PLUS two reserved indices:\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "# broadcast it so that every executor can look up tokens quickly\n",
    "word_index_bc = spark.sparkContext.broadcast(word_index)\n",
    "\n",
    "MAX_LEN = 512\n",
    "\n",
    "# 1) define a Python function to map & pad/truncate\n",
    "def to_padded_indices(tokens):\n",
    "    # tokens: List[str]\n",
    "    idxs = []\n",
    "    wi  = word_index_bc.value\n",
    "    for t in tokens:\n",
    "        idxs.append( wi.get(t, UNK_IDX) )\n",
    "    # pad\n",
    "    if len(idxs) < MAX_LEN:\n",
    "        idxs = idxs + [PAD_IDX] * (MAX_LEN - len(idxs))\n",
    "    else:\n",
    "        idxs = idxs[:MAX_LEN]\n",
    "    return idxs\n",
    "\n",
    "# 2) wrap it as a UDF returning Array[int]\n",
    "to_padded_udf = udf(to_padded_indices, ArrayType(IntegerType()))\n",
    "\n",
    "# 3) apply it\n",
    "df2 = train_text_df.withColumn(\n",
    "    \"seq_padded\",\n",
    "    to_padded_udf(col(\"tokenized_text\"))\n",
    ")\n",
    "\n",
    "# 4) peek\n",
    "df2.select(\"tokenized_text\",\"seq_padded\").show(3, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4004baf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "homl3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
